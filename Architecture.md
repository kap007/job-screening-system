# Multi-Agent AI Framework for Automated Job Screening

**Introduction:** This report outlines the design of a multi-agent AI system for automating job applicant screening using **LangChain** and on-premises **Ollama**-hosted LLMs. The goal is to streamline the recruitment screening process by having specialized AI agents handle each step: summarizing job descriptions (JDs), parsing candidate resumes, matching profiles to job requirements via embeddings, and drafting personalized interview invitation emails for top matches. All components will use open-source tools and models, ensuring data remains on-premise. We also describe an agent architecture with a message bus for inter-agent communication, persistent memory via SQLite, and direct email integration via SMTP. 

This framework aims to mimic an Applicant Tracking System (ATS) but with AI-powered intelligence. By dividing tasks among multiple specialized agents, the system achieves **modularity and specialization**, making it easier to develop and maintain ([Multi-agent Systems](https://langchain-ai.github.io/langgraph/concepts/multi_agent/#:~:text=The%20primary%20benefits%20of%20using,agent%20systems%20are)). Each agent focuses on a specific function (e.g. resume parsing or scoring), and a central orchestrator coordinates their work. Below, we detail the architecture, agent responsibilities, workflow, and recommended open-source tools for each component.

## Architecture Overview

The system follows a **multi-agent supervisor architecture** ([Multi-agent Systems](https://langchain-ai.github.io/langgraph/concepts/multi_agent/#:~:text=,51%20a%20supervisor%20of)) where a central Orchestrator Agent oversees specialized sub-agents. The agents communicate through an **event-driven message bus**, allowing them to operate asynchronously and in parallel when appropriate. Using a message broker (e.g. RabbitMQ or similar) for agent communication decouples the agents: one agent can publish a message (such as a parsed resume or JD summary) to a queue or topic, and another agent subscribed to that channel will consume it ([Integration of a Message Broker for Agent Communication · langchain-ai langchain · Discussion #4671 · GitHub](https://github.com/langchain-ai/langchain/discussions/4671#:~:text=For%20example%20RabbitMQ)). This design enables scaling (e.g. multiple Resume Parser agents processing different resumes concurrently) and fault isolation.

**Workflow:** When a new job description CSV is uploaded or a new resume is received, the Orchestrator triggers the respective agent via the message bus. For example, the Orchestrator can publish a "JD_uploaded" event containing the raw job description text. The JD Summarizer Agent consumes this, processes it, then publishes a "JD_summary" event. Resume Parser Agents pick up "new_resume" events (each containing a resume file path or content), parse the resume, and emit a structured "resume_profile" message. The Matcher Agent listens for pairs of JD summaries and resume profiles to compute a similarity score. If the score exceeds a threshold (e.g. 80%), the system triggers the Email Agent to draft and send an interview email. All interactions, intermediate data (summaries, parsed fields, scores), and decisions are logged in a **SQLite** database for persistence and later retrieval. LangChain's support for persistent memory (e.g. using a `SQLiteEntityStore`) can be leveraged to store these details in a file-backed database ([SQLite | ️ LangChain](https://python.langchain.com/docs/integrations/memory/sqlite/#:~:text=In%20this%20walkthrough%20we%27ll%20create,SqliteEntityStore)).

**Persistent Memory:** The SQLite database serves as the system's long-term memory and audit log. Each agent can read/write to the database: for instance, the JD Summarizer stores the extracted key skills and requirements for the job; resume parsers store the candidate’s extracted qualifications and contact info; the Matcher records the similarity scores, and the Email Agent logs whether an email was sent. This ensures that even if the system restarts, it remembers which candidates have been processed and contacted (the memory is not just in RAM). LangChain natively supports using SQLite for storing conversation or agent state ([SQLite | ️ LangChain](https://python.langchain.com/docs/integrations/memory/sqlite/#:~:text=In%20this%20walkthrough%20we%27ll%20create,SqliteEntityStore)), which we can repurpose to store our agents’ outputs (though here the "conversation" is between agents).

**Message Bus:** For inter-agent communication, a **message broker** like **RabbitMQ** is recommended (open-source and widely used). Each agent could have an inbound queue (its "inbox"), and there could be broadcast topics for certain messages. For example, the JD Summarizer might broadcast the completed JD summary on a topic that all Matcher agents subscribe to, so that multiple resume matchers can use it ([Integration of a Message Broker for Agent Communication · langchain-ai langchain · Discussion #4671 · GitHub](https://github.com/langchain-ai/langchain/discussions/4671#:~:text=For%20example%20RabbitMQ)). RabbitMQ allows flexible routing (direct queues, fan-out, topics) to implement this. This decoupling means agents don’t call each other directly – they just emit or listen for messages, enabling an event-driven flow. This design aligns with enterprise message-driven architectures and lets the system scale horizontally by adding more agents of a given type if needed.

The figure below summarizes the workflow in steps (the numbers correspond to agent activities described in the next section):

1. **JD Ingestion:** Orchestrator receives a new job posting (CSV input) and sends the text to JD Summarizer.
2. **JD Summarization:** JD Summarizer Agent extracts key qualifications and posts the summary to a message topic (and DB).
3. **Resume Ingestion:** Each new resume PDF triggers the Resume Parser Agent via the bus.
4. **Resume Parsing:** Resume Parser extracts structured data (education, skills, etc.) and sends a profile object to Matcher.
5. **Matching & Scoring:** Matcher Agent retrieves the JD summary (from DB or message) and computes a match score via embeddings. It publishes the score (and candidate info) to a "results" channel or directly notifies the orchestrator.
6. **Shortlisting Decision:** Orchestrator (or Matcher) checks the score; if above threshold, it triggers the Email Agent.
7. **Email Generation & Sending:** Email Agent drafts a personalized interview invitation and sends it via SMTP. It logs the email sent event (and could publish a confirmation message).
8. **Logging:** All agents log their outputs to SQLite for persistence. The orchestrator can query this for reporting or to avoid re-processing the same inputs.

## Agent Roles and Workflow

Below we define each agent in the system, including its responsibilities, the tools/LLMs it utilizes, and how it interfaces with others. The agents operate under the coordination of the Orchestrator which ensures the correct sequencing (using the message bus events to hand off control).

### 1. Job Description Summarizer Agent  
**Role:** Ingest a raw job description (from the CSV file) and produce a concise summary of the key points: required skills, qualifications, responsibilities, and other pertinent criteria. The output is a structured summary that other agents (and humans) can easily use for comparison.

**Operation:** The agent reads the job description text from the CSV (which may include job title, responsibilities, required skills, experience, education etc.). It then uses an LLM to analyze and extract the important information. A prompt can be designed to ensure consistent output format – for example, instruct the LLM to list the **Job Title**, **Responsibilities**, and **Requirements/Qualifications** separately ([Summarize a job description with OpenAI, LangChain, and Streamlit | by Ednalyn C. De Dios | Data Science Nerd](https://datasciencenerd.us/summarize-a-job-description-with-openai-langchain-and-streamlit-ae0a1851d390#:~:text=Please%20analyze%20this%20job%20description,and%20categorize%20them%20as%20follows)). We can explicitly ask it to identify required skills, years of experience, education level, and certifications, as these are usually in JDs ([Summarize a job description with OpenAI, LangChain, and Streamlit | by Ednalyn C. De Dios | Data Science Nerd](https://datasciencenerd.us/summarize-a-job-description-with-openai-langchain-and-streamlit-ae0a1851d390#:~:text=,as%20education%2C%20experience%2C%20and%20certifications)). The LLM (running locally via Ollama) will output a summary, which this agent can structure into a JSON (e.g. `{"job_title": ..., "skills": [...], "responsibilities": [...], "qualifications": [...]}`) for downstream use.

**LLM Model:** Because this is an **on-premises** setup, we will use an open-source model served through **Ollama**. **Ollama** makes it easy to run models like Llama 2 or Mistral locally ([Ollama and LangChain: Run LLMs locally | by Abonia Sojasingarayar | Medium](https://medium.com/@abonia/ollama-and-langchain-run-llms-locally-900931914a46#:~:text=In%20the%20realm%20of%20Large,of%20LLMs%20for%20your%20projects)). For summarization tasks, a model fine-tuned for instruction following is ideal. For example, **Llama 2 13B Chat** (or a smaller variant if resources are limited) can be used via the LangChain-Ollama integration to generate the summary. The agent could be implemented with a LangChain LLMChain: a PromptTemplate for extracting JD info, and the Ollama LLM as the backend. The key benefit is that no data leaves the premises – the JD is processed by the local model.

**Output:** The agent publishes the summary to the message bus (e.g., sends a message `JD_summary_ready` with the structured summary). It also writes the summary into the SQLite DB, keyed by job ID or title. This allows the Matching Agent to retrieve job requirements later without re-running the LLM each time. For example, if multiple resumes need to be matched to this JD, the summary is computed once and reused.

### 2. Resume Parsing Agent  
**Role:** Convert an unstructured resume document (PDF or Word) into a structured profile of the candidate. This includes extracting the candidate’s name, contact info, education history, work experience, technical skills, certifications, and notable achievements.

**Document Ingestion:** The agent first needs to extract text from the resume file. We leverage a **PDF parsing library** for this. LangChain integrates with several PDF parsers and loaders ([How to load PDFs | ️ LangChain](https://python.langchain.com/v0.2/docs/how_to/document_loader_pdf/#:~:text=LangChain%20integrates%20with%20a%20host,Below%20we%20enumerate%20the%20possibilities)). A recommended choice is **PyMuPDF** (via LangChain’s `PyMuPDFLoader`), known for its speed and accuracy in extracting text and metadata from PDFs ([Langchain Pdf Pypdfloader Overview — Restack](https://www.restack.io/docs/langchain-knowledge-pdf-pypdfloader-cat-ai#:~:text=Using%20PyMuPDFLoader)). PyMuPDF can reliably get all textual content from the resume, preserving paragraph structure and even splitting by page if needed. This ensures the resume’s content is ready for analysis. (If the resumes were in Word `.docx`, we could use a similar approach with python-docx or other text extractors.)

**Information Extraction:** After getting the raw text, the Resume Parser Agent uses an LLM or NLP pipeline to identify key sections. Many resumes have headings like *Education*, *Work Experience*, *Skills*, etc. The agent can prompt an LLM to parse the text and fill a structured template. For example, a prompt could be: *"Extract the following fields from the resume: Full Name, Email, Phone, Education (degrees and years), Work Experience (roles, companies, and durations), Skills, Certifications, Achievements. Output as JSON."* An Ollama-hosted model (like Llama 2 or an instruct fine-tuned model) can handle this extraction with few-shot examples if needed. Using an LLM for parsing leverages its understanding of varied resume formats to pull out the right data (similar to how GPT-based resume parsers work, but here using an open model). 

Alternatively, for a purely rule-based approach, the agent could use NLP libraries like **spaCy** to find entities (names, dates, etc.) and keywords (e.g., degrees, university names) in the text. Indeed, some open-source resume parsing tools combine spaCy/NLTK for keyword extraction with vector similarity ([Creating a Game-Changer in Job Search: An Open Source ATS Resume Matcher - DEV Community](https://dev.to/srbhr/creating-a-game-changer-in-job-search-an-open-source-ats-resume-matcher-31g9#:~:text=This%20Python,Provide%20keyword%20analysis%2C%20matching%20keywords)). However, an LLM approach may be simpler and more flexible in handling arbitrary formats. We can also combine strategies: use regex for known patterns (emails, phone numbers), spaCy for names, and LLM for structuring experiences.

**Output:** The result is a structured profile, e.g.:
```json
{
  "name": "Alyssa Chavez",
  "contact": {"email": "alyssachavez88@gmail.com", "phone": "+1-465-3587"},
  "education": ["Diploma in Software Engineering (2013-2015)"],
  "experience": ["Data Scientist at ABC Inc. (2019-2023) - built predictive models ...", "..."],
  "skills": ["Full-stack development", "Data Science", "Python", "..."],
  "certifications": [...],
  "achievements": [...]
}
``` 
This profile is sent as a message (e.g., `resume_parsed`) on the bus, and also saved to the SQLite database. Storing it allows the system to later enrich or review candidate data, and it provides the Matcher agent quick access to specific fields (like skills list).

### 3. Profile Matching & Scoring Agent  
**Role:** Determine how well a candidate’s profile matches the job requirements. This agent takes a JD summary and a candidate’s parsed resume profile, and computes a **match score** (e.g., 0–100 or 0–1) based on similarity of skills, experience, and qualifications. It essentially answers, "How good of a fit is this candidate for the job?"

**Approach:** We use a **semantic vector matching** approach to quantify the match. Both the job description (or its summary) and the candidate's profile are converted into embedding vectors in a high-dimensional space. The similarity between these vectors (often measured by cosine similarity) correlates with how semantically similar the texts are ([MATCHING RESUMES WITH JD USING UNIVERSAL SENTENCE ENCODER(USE) | by Varshni | Tech Musings](https://techmusings.optisolbusiness.com/matching-resumes-with-jd-using-universal-sentence-encoder-use-4a757fe77da8#:~:text=1,that%20matches%20the%20job%20description)). For instance, if the JD emphasizes machine learning and Python, and the resume also heavily features those, the cosine similarity will be high.

**Embedding Model:** We will use an **open-source embedding model** to generate the vectors. One option is the **Universal Sentence Encoder (USE)**, which was used in prior work on resume-JD matching ([MATCHING RESUMES WITH JD USING UNIVERSAL SENTENCE ENCODER(USE) | by Varshni | Tech Musings](https://techmusings.optisolbusiness.com/matching-resumes-with-jd-using-universal-sentence-encoder-use-4a757fe77da8#:~:text=UNIVERSAL%20SENTENCE%20ENCODER)) ([MATCHING RESUMES WITH JD USING UNIVERSAL SENTENCE ENCODER(USE) | by Varshni | Tech Musings](https://techmusings.optisolbusiness.com/matching-resumes-with-jd-using-universal-sentence-encoder-use-4a757fe77da8#:~:text=1,that%20matches%20the%20job%20description)). USE can encode texts into a 512-dimensional vector and has been shown to work well for semantic similarity of documents. It’s available as a TensorFlow model (which can be run on-premise). Alternatively, **Sentence-Transformers** models (from HuggingFace) are a great choice – e.g., `all-MiniLM-L6-v2` (a lightweight 384-dim model) or `multi-qa-MiniLM-cos-v1`. These models are small, fast, and capture a lot of semantic information. We could also consider newer open models like **GTE** or **E5** for embeddings ([Graft - 15 Best Open Source Text Embedding Models](https://www.graft.com/blog/open-source-text-embedding-models#:~:text=4.%20E5)). Since we are already using Ollama for LLMs, one could integrate a local embedding model into the pipeline via LangChain's embedding classes (for instance, using `HuggingFaceEmbeddings` with a downloaded model). The key is that the same embedding model must be used for both the resumes and the JD to make the vectors comparable ([MATCHING RESUMES WITH JD USING UNIVERSAL SENTENCE ENCODER(USE) | by Varshni | Tech Musings](https://techmusings.optisolbusiness.com/matching-resumes-with-jd-using-universal-sentence-encoder-use-4a757fe77da8#:~:text=1,that%20matches%20the%20job%20description)).

**Scoring:** The agent will take the JD's embedding and each resume’s embedding and compute a **cosine similarity**. Cosine similarity results in a value from -1 to 1; since all text embeddings are typically positive space, the range is 0 (no similarity) to 1 (identical text). We can multiply by 100 to get a percentage match. This score reflects overall semantic match. In practice, many systems also weight specific key skills – we could augment the score by giving extra points if certain required skills (from the JD summary) appear explicitly in the resume. For example, if the JD requires "SQL" and the candidate’s skills include "SQL", we might boost the score. The Matching Agent can incorporate such rules in addition to the base similarity. However, even without manual weighting, embedding similarity often naturally captures keyword overlap ([MATCHING RESUMES WITH JD USING UNIVERSAL SENTENCE ENCODER(USE) | by Varshni | Tech Musings](https://techmusings.optisolbusiness.com/matching-resumes-with-jd-using-universal-sentence-encoder-use-4a757fe77da8#:~:text=1,that%20matches%20the%20job%20description)).

**Output:** The agent outputs a score for each (resume, JD) pair. If processing resumes one by one, it will attach the candidate ID and job ID with the score. It then emits a message like `match_score` with the data, and logs it to SQLite. It could also directly decide if the candidate is a "pass" or "shortlist" based on the threshold. For example, if the threshold is 80%, a cosine similarity of 0.82 (82%) triggers a positive outcome. The agent (or orchestrator) then forwards those above threshold to the next step. In our design, we assume the Orchestrator monitors the scores: it receives the `match_score` events and checks the value. For scores >= 0.8 (or 80%), it will issue an `invite_candidate` event for the Email Agent. Lower scored candidates might trigger a different action (perhaps an automated rejection email or simply no action; not explicitly required here, so they could just be logged as not shortlisted).

**Note:** Instead of computing each comparison on the fly, another design is to use a **vector database**. For instance, we could store all resume embeddings in a vector store (like **ChromaDB** or an **SQLite with vector extension** ([SQLite as a Vector Store with SQLiteVec - ️ LangChain](https://python.langchain.com/docs/integrations/vectorstores/sqlitevec/#:~:text=SQLite,into%20applications%20without%20external))). The JD embedding can then be used to query the DB for the top-N similar candidates. This is efficient if you have a large pool of candidates. However, in our scenario, processing is batch-oriented (we compute scores as resumes come), so a full vector index might not be necessary. Still, as an open-source component, Chroma or SQLite-Vec could be plugged in if we wanted persistent vector storage and more advanced querying.

### 4. Email Communication Agent  
**Role:** For each shortlisted candidate, generate a personalized interview invitation email and send it via SMTP. This agent ensures that promising applicants are contacted promptly with a well-crafted message that includes details relevant to them and the job.

**Email Drafting:** We use an LLM to create a polite, professional email template and personalize it with the candidate’s name, the position title, and possibly a brief mention of match. For example, the prompt to the LLM could be: *"Compose a friendly email inviting [Candidate Name] to an interview for the [Job Title] position at [Company]. Mention that her experience in [key skill from resume] would be valuable to the role. Provide details about possible interview times and how to respond."* The JD summary and candidate profile can be provided as context to help the model tailor the message (especially to highlight a particular strength of the candidate that matched the JD). Since this is a sensitive communication, we will likely review the template output or constrain the LLM with a fixed template and just fill in blanks. A simpler approach is to prepare an email template with placeholders and let the LLM or code fill them, rather than free-form generation. However, using the LLM can yield more varied and human-like phrasing for the email body.

**LLM Model:** A smaller model might suffice here (even a 7B parameter model or a fine-tuned GPT-2 level model) since the task is more straightforward. But since we already have Llama 2 running, we can reuse it for email generation, or use a specialized polite-text generator. The agent can use LangChain to format the output in an email style (with proper salutation, body, closing). 

**SMTP Sending:** After generating the email text, the agent uses an SMTP client to actually send the email to the candidate's address. This can be done with Python's built-in `smtplib` library ([Python Send Email: Tutorial with Code Snippets [2025] - Mailtrap](https://mailtrap.io/blog/python-send-email/#:~:text=Mailtrap%20mailtrap,core%20functions%20to%20send%20emails)) ([smtplib — SMTP protocol client — Python 3.13.3 documentation](https://docs.python.org/3/library/smtplib.html#:~:text=smtplib%20%E2%80%94%20SMTP%20protocol%20client,SMTP%20or%20ESMTP%20listener%20daemon)). The SMTP server could be an on-prem email server or a service like Gmail/Outlook if configured. For example, using Gmail’s SMTP (smtp.gmail.com) with appropriate credentials in a secure manner (not hardcoded) is a simple way to send emails ([Sending Emails With Python - Real Python](https://realpython.com/python-send-email/#:~:text=Sending%20Emails%20With%20Python%20,Although%20the%20majority%20of)). Since we aim for an open-source solution, one could also set up an open-source mail server (like Postfix or an SMTP relay) internally. The agent will format the email with necessary headers (To, From, Subject, MIME format for text or HTML) using Python's `email` library and then send via `smtplib` ([Python Send Email: Tutorial with Code Snippets [2025] - Mailtrap](https://mailtrap.io/blog/python-send-email/#:~:text=Mailtrap%20mailtrap,core%20functions%20to%20send%20emails)). This step is straightforward once the content is ready. The Email Agent can be implemented as a tool in LangChain as well – LangChain has integrations for email (like a Gmail API tool), but using SMTP directly keeps it on-prem and open.

**Output:** The Email Agent logs the email activity to SQLite (e.g., storing timestamp, candidate email, subject, and a flag that it was sent). If using a message bus, it could also emit an `email_sent` confirmation message. Any SMTP failures (e.g., invalid address) could be caught and handled – perhaps notifying the orchestrator or logging an error.

### 5. Orchestrator Agent (Controller)  
**Role:** While not explicitly listed in the requirements, the Orchestrator is implied by the use of a supervisor architecture. This agent (or simple control loop) coordinates the entire workflow and connects the other agents via the message bus. It does not use an LLM for decision-making (the flow is mostly deterministic), but it ensures each piece runs in order.

**Responsibilities:** The Orchestrator monitors incoming data sources (the CSV for jobs, a directory or interface for resumes) and triggers the appropriate processing:
- When a new JD is found, instruct JD Summarizer Agent to process it (e.g., by sending a message or calling its chain).
- For each new resume, send it to a Resume Parser Agent (could be round-robin if multiple parser instances).
- Ensure that the JD summary is available to the Matcher (could wait for JD Summarizer to finish before allowing matching, or simply let Matcher fetch summary from DB when needed).
- Receive match scores from the Matcher Agent and decide if they exceed the threshold. This logic can be a simple if/else check in code. Shortlisted candidates are then passed to Email Agent.
- Handle any retries or failures (if an agent does not produce output, orchestrator could time out and log errors).
- Terminate or archive the workflow when done.

The Orchestrator essentially encodes the business rules (like the 80% cutoff) and sequence. It uses the **message bus** to subscribe to events or simply waits for responses in a synchronous chain. An advanced implementation might not need an explicit orchestrator if using something like LangChain's **LangGraph** to define the flow in a declarative way (LangChain's experimental framework for multi-agent workflows). But a Python controller script using queues is straightforward.

**Inter-agent Communication:** We have chosen RabbitMQ as an example broker for its reliability. Each agent can be a separate process or service listening to RabbitMQ queues. For instance:
- JD Summarizer listens on `job_desc_queue` and upon receiving a message with JD text, processes and sends a message to `jd_summary_queue`.
- Resume Parser listens on `resume_queue` for new resume file paths.
- Matcher listens on `match_queue` which could receive a combined payload (JD summary + one resume profile) or the agent could fetch the JD summary from DB when it gets a resume event.
- Email Agent listens on `email_queue` for messages containing candidate contact and job info when an interview invite needs to be sent.
The Orchestrator can send messages to these queues or use routing keys. In RabbitMQ, we might set up a **topic exchange** where the JD summary is broadcast to all services that need it ([Integration of a Message Broker for Agent Communication · langchain-ai langchain · Discussion #4671 · GitHub](https://github.com/langchain-ai/langchain/discussions/4671#:~:text=For%20example%20RabbitMQ)). For simplicity, direct queues for each agent type are fine. The message bus decoupling means, for example, the Resume Parser doesn’t need to know about the Matcher at all; it just outputs to a queue which the Matcher is watching. This design follows the **event-driven pattern** often seen in microservice architectures, applied here to AI agents.

**Scheduling:** If we need to schedule periodic actions (not strictly necessary in our scenario since events are data-driven), we could integrate a scheduler. For example, if resumes are continuously arriving in a folder, a scheduler could check the folder every minute and push new files into the system. A lightweight option is **APScheduler** (Advanced Python Scheduler) which can schedule function calls at intervals. Another option is to use **Celery** – Celery is a task queue that works with brokers like RabbitMQ/Redis; it could manage the distribution of tasks to agent workers and includes scheduling features. Celery would be perhaps an overkill if we already manage our own message bus, but it's an option to mention. For purely time-based scheduling (like sending summary reports every day), a cron job or APScheduler in the orchestrator could suffice.

## Open-Source Tools and Components Comparison

There are multiple open-source choices for each component of this system. The table below compares key tools/models for each aspect and notes our recommendations:

| **Component**           | **Open-Source Options**                                    | **Pros**                                                            | **Cons**                                                        | **Choice**               |
|-------------------------|------------------------------------------------------------|---------------------------------------------------------------------|-----------------------------------------------------------------|--------------------------|
| **Job Description Summarization (LLM)** | - Llama 2 (13B/7B via Ollama) <br> - **FLAN-T5 XL** (Google) <br> - Mistral 7B | Llama 2: High-quality, instruction-tuned, runs locally ([Ollama and LangChain: Run LLMs locally | by Abonia Sojasingarayar | Medium](https://medium.com/@abonia/ollama-and-langchain-run-llms-locally-900931914a46#:~:text=In%20the%20realm%20of%20Large,of%20LLMs%20for%20your%20projects)). <br> FLAN-T5: Smaller, faster, good at summarization. <br> Mistral: Newer 7B model, very fast on CPU. | Llama 2: Requires more RAM/VRAM (13B model). <br> FLAN-T5: May miss nuances due to smaller size. <br> Mistral: May not be as fluent for longer outputs (still evolving). | **Llama 2 13B** via Ollama for best accuracy; fall back to FLAN-T5 for lower resource. |
| **PDF Resume Parsing**  | - **PyMuPDF** (MuPDF) <br> - PyPDF <br> - Unstructured (organization) | PyMuPDF: Very fast and accurate text extraction from PDF, page by page ([Langchain Pdf Pypdfloader Overview — Restack](https://www.restack.io/docs/langchain-knowledge-pdf-pypdfloader-cat-ai#:~:text=Using%20PyMuPDFLoader)). <br> PyPDF: Pure Python, simple, no external dependencies. <br> Unstructured.io toolkit: Handles complex layouts, images, etc. | PyMuPDF: Requires a C library (MuPDF) but that’s bundled in wheel. <br> PyPDF: Slower on large files, might not preserve layout as well. <br> Unstructured: Heavy dependencies, installation complexity ([Best open source document PARSER??!! : r/LangChain](https://www.reddit.com/r/LangChain/comments/1dicr6p/best_open_source_document_parser/#:~:text=%E2%80%A2)). | **PyMuPDF** (via LangChain's loader) for reliable PDF text extraction. |
| **Resume Information Extraction** | - LLM-based parsing (Llama 2 or GPT-4 open clones) <br> - **spaCy** NLP pipeline <br> - Custom rules/regex | LLM parsing: Adapts to any format, yields structured data with minimal manual effort. <br> spaCy: Very good at NER (names, dates), fast, fully local. <br> Rules: Complete control, no model needed. | LLM: Might occasionally extract incorrect info if prompt isn’t perfect; needs context length to fit entire resume. <br> spaCy: Requires building logic to combine entities into education/work segments. <br> Regex: brittle – resumes vary widely in format. | **LLM-based** parsing (with a validated prompt) for flexibility; use spaCy/regex to assist for specific fields (contacts). |
| **Embedding Model for Matching** | - **Sentence-Transformers** (e.g. all-MiniLM, mpnet) <br> - Universal Sentence Encoder (TF Hub) ([MATCHING RESUMES WITH JD USING UNIVERSAL SENTENCE ENCODER(USE) | by Varshni | Tech Musings](https://techmusings.optisolbusiness.com/matching-resumes-with-jd-using-universal-sentence-encoder-use-4a757fe77da8#:~:text=UNIVERSAL%20SENTENCE%20ENCODER)) <br> - InstructorXL or GTE-large | Sentence-Transformers: Easy to use via HuggingFace, many sizes; all-MiniLM is only 66MB and quick. <br> USE: Proven in resume matching context ([MATCHING RESUMES WITH JD USING UNIVERSAL SENTENCE ENCODER(USE) | by Varshni | Tech Musings](https://techmusings.optisolbusiness.com/matching-resumes-with-jd-using-universal-sentence-encoder-use-4a757fe77da8#:~:text=1,that%20matches%20the%20job%20description)), high-quality embeddings. <br> Instructor/GTE: Latest research models, high accuracy in general similarity. | MiniLM: May miss some nuance due to smaller dimensionality. <br> USE: Requires TensorFlow, not Pythonic Huggingface style. <br> Larger models: more compute and memory needed for marginal gain. | **All-MiniLM-L6-v2** (SentenceTransformer) for speed; if TF environment is okay, test **USE** for slightly better semantic capture. Both are open-source. |
| **Vector Database (optional)** | - **ChromaDB** <br> - FAISS <br> - SQLite VSS (Vector extension) ([SQLite as a Vector Store with SQLiteVec - ️ LangChain](https://python.langchain.com/docs/integrations/vectorstores/sqlitevec/#:~:text=SQLite,into%20applications%20without%20external)) | Chroma: Simple API, persistent or in-memory, integrates with LangChain out-of-the-box. <br> FAISS: Facebook’s library, very optimized for similarity search. <br> SQLite VSS: Allows vector search using just SQLite (with extension), minimal deployment. | Chroma: Running as separate service if used in client-server mode, but can be embedded. <br> FAISS: C++ library, not a DB, so needs custom handling for persistence/sharding. <br> SQLite VSS: Still new, may not be as optimized for large volumes as FAISS. | **ChromaDB** if a vector store is needed, due to ease of use. (Not mandatory for moderate resume volumes – direct computation is fine.) |
| **Message Bus / Broker** | - **RabbitMQ** <br> - Redis (Pub/Sub) <br> - Apache Kafka <br> - ZeroMQ | RabbitMQ: Robust queue & topic system, supports complex routing (ideal for multi-agent workflows) ([Integration of a Message Broker for Agent Communication · langchain-ai langchain · Discussion #4671 · GitHub](https://github.com/langchain-ai/langchain/discussions/4671#:~:text=For%20example%20RabbitMQ)). <br> Redis: Lightweight, can use Pub/Sub channels, also act as cache DB. <br> Kafka: Highly scalable, persistent log of messages (useful if need durable event store). <br> ZeroMQ: Peer-to-peer sockets, no central broker needed. | RabbitMQ: Additional service to maintain; uses AMQP protocol (learning curve). <br> Redis: Pub/Sub has no message persistence or acknowledgment (if an agent is down, message might be lost). <br> Kafka: Overkill for small scale, requires a cluster and JVM. <br> ZeroMQ: No persistence or monitoring – you'd build a lot yourself. | **RabbitMQ** for full-fledged message queuing and reliability. (Redis Pub/Sub if simplicity is prioritized over guaranteed delivery.) |
| **Persistent Data Store** | - **SQLite** <br> - PostgreSQL/MySQL <br> - JSON/CSV Files | SQLite: Zero-config, file-based DB, ACID compliance, good for moderate data, and can even store vectors with extensions ([Langchain Sqlite Integration Guide - Restack](https://www.restack.io/docs/langchain-knowledge-sqlite-integration-cat-ai#:~:text=Langchain%20Sqlite%20Integration%20Guide%20,a%20vector%20store%20within%20LangChain)). <br> Postgres/MySQL: client-server DBs, handle large scale, multiple concurrent connections well. <br> Flat files (CSV/JSON): simplest, human-readable. | SQLite: concurrent writes are limited (single writer at a time), but reads are fine; not ideal if many agents try to log simultaneously (could serialize operations). <br> SQL Servers: Need setup and maintenance; might be unnecessary for relatively small data volume in screening. <br> Files: Harder to query, risk of losing consistency or data if multiple processes write. | **SQLite** for simplicity and because LangChain can integrate with it for memory ([SQLite | ️ LangChain](https://python.langchain.com/docs/integrations/memory/sqlite/#:~:text=In%20this%20walkthrough%20we%27ll%20create,SqliteEntityStore)). If scaling up to millions of records, consider upgrading to PostgreSQL. |
| **Email Delivery**     | - **smtplib (Python)** <br> - Apache James or Postal (self-hosted SMTP server) <br> - Integrations (SendGrid API, etc.) | smtplib (built-in): No external dependencies, directly talk to any SMTP server ([Python Send Email: Tutorial with Code Snippets [2025] - Mailtrap](https://mailtrap.io/blog/python-send-email/#:~:text=Mailtrap%20mailtrap,core%20functions%20to%20send%20emails)). <br> Self-hosted SMTP (James/Postal): Full control of email server, no third-party, handles queuing and retries. <br> Email APIs (SendGrid/Mailgun): high deliverability, ready-made templates (but external services). | smtplib: requires an SMTP service to connect to (e.g., company mail server or Gmail) and careful handling of auth. <br> Hosting SMTP: operational overhead, must manage spam/DMARC, etc. <br> External APIs: Not on-prem (violates purely open-source/on-prem principle, and introduces costs). | **smtplib** with a configured company SMTP or an open-source mail server. Keep things on-prem to maintain data privacy. |

*Table:* **Open-source tools comparison for each component of the job screening system.** The chosen solutions prioritize on-premise deployment, ease of integration with LangChain, and reliability.

## Conclusion

By combining specialized agents with a robust communication and memory backbone, this multi-agent AI framework can fully automate the initial screening of job applicants in an efficient and extensible manner. The use of LangChain enables these agents to be built rapidly by chaining LLM prompts and tools, while on-prem **Ollama**-hosted models ensure that proprietary data (job descriptions and resumes) never leaves the organization's environment ([Ollama and LangChain: Run LLMs locally | by Abonia Sojasingarayar | Medium](https://medium.com/@abonia/ollama-and-langchain-run-llms-locally-900931914a46#:~:text=In%20the%20realm%20of%20Large,of%20LLMs%20for%20your%20projects)). Each agent in the system has a clear responsibility – from analyzing the job requirements ([Summarize a job description with OpenAI, LangChain, and Streamlit | by Ednalyn C. De Dios | Data Science Nerd](https://datasciencenerd.us/summarize-a-job-description-with-openai-langchain-and-streamlit-ae0a1851d390#:~:text=,as%20education%2C%20experience%2C%20and%20certifications)), to extracting resume features, to computing match scores with semantic embeddings ([MATCHING RESUMES WITH JD USING UNIVERSAL SENTENCE ENCODER(USE) | by Varshni | Tech Musings](https://techmusings.optisolbusiness.com/matching-resumes-with-jd-using-universal-sentence-encoder-use-4a757fe77da8#:~:text=1,that%20matches%20the%20job%20description)), and finally communicating with candidates – which follows the principle of modularity in multi-agent design ([Multi-agent Systems](https://langchain-ai.github.io/langgraph/concepts/multi_agent/#:~:text=The%20primary%20benefits%20of%20using,agent%20systems%20are)). 

All components utilize open-source technologies, from the LLMs and embedding models to the infrastructure (SQLite, RabbitMQ, etc.), aligning with the requirement to avoid closed-source or cloud-dependent tools. The framework also logs its decisions and intermediate data for transparency and continuous improvement; for example, HR teams can review what skills the AI identified from a JD or why a particular candidate was marked as a good match (via the stored scores and summary data). 

In summary, the proposed system is a blueprint for an AI-powered applicant tracking workflow that can be deployed entirely on-premise. It leverages the latest advancements in natural language processing – large language models and embeddings – within a structured, message-driven architecture. This ensures both **intelligence** in decision-making and **robustness** in operation. Adopting this design can dramatically reduce the manual effort of resume screening while maintaining (or improving) the quality of hires by consistently measuring each candidate against the job criteria in a data-driven way. The modular agent approach also means the system can be extended (for instance, adding an agent to schedule interview appointments or to provide feedback to unselected candidates) without a complete overhaul, demonstrating the flexibility of multi-agent AI architectures in real-world enterprise applications. 

**Sources:**

- LangChain multi-agent system benefits and architecture ([Multi-agent Systems](https://langchain-ai.github.io/langgraph/concepts/multi_agent/#:~:text=The%20primary%20benefits%20of%20using,agent%20systems%20are)) ([Multi-agent Systems](https://langchain-ai.github.io/langgraph/concepts/multi_agent/#:~:text=,51%20a%20supervisor%20of))  
- Message broker for agent communication (RabbitMQ example) ([Integration of a Message Broker for Agent Communication · langchain-ai langchain · Discussion #4671 · GitHub](https://github.com/langchain-ai/langchain/discussions/4671#:~:text=For%20example%20RabbitMQ))  
- LangChain PDF parsing (PyMuPDF loader speed and usage) ([Langchain Pdf Pypdfloader Overview — Restack](https://www.restack.io/docs/langchain-knowledge-pdf-pypdfloader-cat-ai#:~:text=Using%20PyMuPDFLoader))  
- LLM prompt for extracting JD skills/requirements ([Summarize a job description with OpenAI, LangChain, and Streamlit | by Ednalyn C. De Dios | Data Science Nerd](https://datasciencenerd.us/summarize-a-job-description-with-openai-langchain-and-streamlit-ae0a1851d390#:~:text=Please%20analyze%20this%20job%20description,and%20categorize%20them%20as%20follows)) ([Summarize a job description with OpenAI, LangChain, and Streamlit | by Ednalyn C. De Dios | Data Science Nerd](https://datasciencenerd.us/summarize-a-job-description-with-openai-langchain-and-streamlit-ae0a1851d390#:~:text=,as%20education%2C%20experience%2C%20and%20certifications))  
- Resume-JD matching via embeddings and cosine similarity ([MATCHING RESUMES WITH JD USING UNIVERSAL SENTENCE ENCODER(USE) | by Varshni | Tech Musings](https://techmusings.optisolbusiness.com/matching-resumes-with-jd-using-universal-sentence-encoder-use-4a757fe77da8#:~:text=1,that%20matches%20the%20job%20description))  
- Open-source resume matcher using NLP and semantic similarity ([Creating a Game-Changer in Job Search: An Open Source ATS Resume Matcher - DEV Community](https://dev.to/srbhr/creating-a-game-changer-in-job-search-an-open-source-ats-resume-matcher-31g9#:~:text=This%20Python,Provide%20keyword%20analysis%2C%20matching%20keywords))  
- Ollama for running local LLMs with LangChain
